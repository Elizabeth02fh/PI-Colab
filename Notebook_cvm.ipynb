{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"\\\\Dataset\\\\\"\n",
    "files = glob.glob(path + \"/*precios*\")\n",
    "#un solo archivo\n",
    "#new=glob.glob(path + \"/precios_semana_20200413.csv\")#para la carga incremental\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de archivos generalizada\n",
    "\n",
    "Si Fer, pero con el csv pasa que tienen diferente encodig y solo me fije ahora entonces es mas embole cambierlo.\n",
    "Si le agrugue lo del parquet, entonces producto si se podria leer asi de una vez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path): \n",
    "\n",
    "    for i in path:\n",
    "        ext = os.path.splitext(i)[-1].lower() #deja solo las extensiones\n",
    "        if ext=='.xlsx':\n",
    "            xls = pd.ExcelFile(i)\n",
    "            sheets=xls.sheet_names\n",
    "            if len(sheets)==1:\n",
    "                df=pd.read_excel(i)\n",
    "                return df\n",
    "            elif len(sheets)==2:\n",
    "                df1=pd.read_excel(i,sheet_name=0).assign(semana=sheets[0])\n",
    "                df2=pd.read_excel(i,sheet_name=1).assign(semana=sheets[1])\n",
    "                return df1, df2\n",
    "            else:\n",
    "                print('Archivo Excel con mas de dos sheets')\n",
    "        elif ext=='.csv' or ext=='.txt':\n",
    "            df=pd.read_csv(i,sep=',',encoding='utf-16').assign(semana=os.path.basename(i).split('.')[0])\n",
    "            return df\n",
    "        elif ext=='.json':\n",
    "            df=pd.read_json(i).assign(semana=os.path.basename(i).split('.')[0])\n",
    "            return df\n",
    "        elif ext=='.parquet':\n",
    "            df=pd.read_parquet(i)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"I just can't\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lectura de archivos (FER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo archivos de precio (Tabla de hechos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precios = pd.read_excel(files[0], dtype=object ,sheet_name=1)\n",
    "df_precios1 = pd.read_excel(files[0], sheet_name=0)\n",
    "df_precios2 = pd.read_csv(files[1],sep=',',encoding='utf-16')\n",
    "df_precios3 = pd.read_json(files[2])\n",
    "df_delta = pd.read_csv(files[-1], sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla sucursal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sucu_file = glob.glob(path + \"/*sucursal*\")\n",
    "sucursal = pd.read_csv(sucu_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla de producto y ETL\n",
    "\n",
    "perdon, ya tengo suenho y no lo uni a la parte de ETL jaja pero, ya con esto se sube al postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "      <th>categoria1</th>\n",
       "      <th>categoria2</th>\n",
       "      <th>categoria3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25198</th>\n",
       "      <td>7790520015679</td>\n",
       "      <td>GLADE</td>\n",
       "      <td>Repuesto Aromatizante Dulce Tentacion Glade Ac...</td>\n",
       "      <td>1.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71037</th>\n",
       "      <td>9-2-0000000366861</td>\n",
       "      <td>SIN MARCA</td>\n",
       "      <td>Queso Rallado en Sobre 1 Kg</td>\n",
       "      <td>1.0 kg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0000077965691</td>\n",
       "      <td>MENTHOPLUS</td>\n",
       "      <td>Caramelo sin Azucar Sandia Menthoplus 26.6 Gr</td>\n",
       "      <td>26.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       marca  \\\n",
       "25198      7790520015679       GLADE   \n",
       "71037  9-2-0000000366861   SIN MARCA   \n",
       "448        0000077965691  MENTHOPLUS   \n",
       "\n",
       "                                                  nombre presentacion  \\\n",
       "25198  Repuesto Aromatizante Dulce Tentacion Glade Ac...       1.0 un   \n",
       "71037                        Queso Rallado en Sobre 1 Kg       1.0 kg   \n",
       "448        Caramelo sin Azucar Sandia Menthoplus 26.6 Gr      26.0 gr   \n",
       "\n",
       "      categoria1 categoria2 categoria3  \n",
       "25198       None       None       None  \n",
       "71037       None       None       None  \n",
       "448         None       None       None  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1=glob.glob(path + \"/producto.parquet\")\n",
    "producto=read_file(path1)\n",
    "producto.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "marca               2\n",
       "nombre              2\n",
       "presentacion        2\n",
       "categoria1      72034\n",
       "categoria2      72034\n",
       "categoria3      72034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veamos los nulos\n",
    "producto.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000001663</td>\n",
       "      <td>LA ANÓNIMA</td>\n",
       "      <td>Radicheta Atada La Anonima 1 Un</td>\n",
       "      <td>1.0 un</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       marca                           nombre presentacion\n",
       "0  0000000001663  LA ANÓNIMA  Radicheta Atada La Anonima 1 Un       1.0 un"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se eliminaran las columnas categoria\n",
    "producto.drop(columns=['categoria1','categoria2','categoria3'], inplace=True)\n",
    "producto.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_change(x):\n",
    "    if isinstance(x,str):\n",
    "        x = x.split('-')[-1]\n",
    "    elif isinstance(x,float):\n",
    "        x = int(x)\n",
    "    else:    \n",
    "        x=x\n",
    "    return int(x)\n",
    "\n",
    "producto.id = producto.id.apply(id_change)\n",
    "\n",
    "producto.drop_duplicates(subset=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=glob.glob(path + \"/precios_semanas_20200419_20200426.xlsx\")\n",
    "prueba1, prueba2=read_file(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformacion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>FER:</u>  \n",
    "-  La funcion unDate(x) trabajaba a nivel Serie y originalmente estaba pensada para ser usada en un .apply(), por eso no estaba funcionando. Para corregirlo (no estoy seguro de que sea la mejor manera), la renombre a unDateSeries(x) y cree una unDate(df) que recibe un df y aplica unDateSeries a la serie Sucursal_id.  \n",
    "-  La typeCheck() para la parte de producto no funcionaba porque trataba de aplicar la funcion en forma vectorizaa sin tener en cuenta los diferentes casos dentro de una misma columna de manera correcta. Ya modifique y quedó funcionando todo.\n",
    "**A revisar**  \n",
    "La carga de archivos automatizada no contempla el hecho de que la segunda hoja del sheet tiene datos anteriores a la primera hoja (estan invertidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unDate(df):\n",
    "    \n",
    "    def unDateSeries(x):\n",
    "        \"\"\"read_excel me trae algunas sucursal_id como si fueran datetime. Esta funcion toma elementos de una serie, \n",
    "           chequea si son datetime y en caso de serlo, los convierte a str con el formato acorde al orden de identificadores de sucursal\"\"\"\n",
    "        if isinstance(x,datetime):\n",
    "            x=x.strftime(\"%#d-%#m-%Y\")\n",
    "        return x\n",
    "\n",
    "    df.sucursal_id = df.sucursal_id.apply(unDateSeries)\n",
    "    return df \n",
    "\n",
    "def nasDups(df):\n",
    "    \"\"\"Cosas básicas: remover duplicados y nulos\"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def typeCheck(df):\n",
    "    \"\"\"En base a la exploracion inicial, se detectaron errores comunes en los diferentes campos. \n",
    "       Esta funcion soluciona todos los problemas encontrados en los diferentes archivos de la fuente de datos\"\"\"\n",
    "\n",
    "    if df.precio.dtype != \"float\":\n",
    "        \"\"\"Algunos precios llegan con un string vacio en vez de nulo. Los convertimos a None para removerlos despues. \n",
    "           A los que tienen valores, los convertimos a float\"\"\"\n",
    "        try:\n",
    "            df.precio = df.precio.apply(lambda x: None if x == '' else x)\n",
    "            df.precio = df.precio.astype(float)\n",
    "        except:\n",
    "            print(\"Error type precios\")\n",
    "\n",
    "    if df.sucursal_id.dtype != \"str\":\n",
    "        try:\n",
    "            df.sucursal_id = df.sucursal_id.astype('string')\n",
    "        except:\n",
    "            print('Error type sucursal_id')\n",
    "            \n",
    "    def prod(x):\n",
    "        if isinstance(x,str):\n",
    "            x = x.split('-')[-1]\n",
    "        elif isinstance(x,float):\n",
    "            x = int(x)\n",
    "        else:    \n",
    "            x=x\n",
    "        return int(x)\n",
    "    df.producto_id = df.producto_id.apply(prod)\n",
    "\n",
    "    return df\n",
    "\n",
    "def splitProd(df):\n",
    "    \"\"\"Algunos productos tenian hardcodeada la sucursal. Removemos esa porcion del string y nos quedamos \n",
    "       unicamente con el codigo de producto (12-13 char)\"\"\"\n",
    "    df.producto_id = df.producto_id.str.split('-').str[-1]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregué etl_sucu que solamente aplica los tipos de datos adecuados para compatiblidad con POSTGRES (no estoy seguro de que sea realmente necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl(df):\n",
    "    df = nasDups(df)\n",
    "    df = unDate(df)\n",
    "    df = typeCheck(df)\n",
    "    #df = splitProd(df)\n",
    "    return df\n",
    "\n",
    "def etl_sucu(sucursal):\n",
    "    sucursal.id=sucursal.id.astype('string')    \n",
    "    sucursal.comercioId = sucursal.comercioId.astype(int)\n",
    "    sucursal.banderaId = sucursal.banderaId.astype(int)\n",
    "    sucursal.banderaDescripcion = sucursal.banderaDescripcion.astype('string')\n",
    "    sucursal.comercioRazonSocial = sucursal.comercioRazonSocial.astype('string')\n",
    "    sucursal.provincia = sucursal.provincia.astype('string')\n",
    "    sucursal.localidad = sucursal.localidad.astype('string')\n",
    "    sucursal.direccion = sucursal.direccion.astype('string')\n",
    "    sucursal.sucursalNombre = sucursal.sucursalNombre.astype('string')\n",
    "    sucursal.sucursalTipo = sucursal.sucursalTipo.astype('string')\n",
    "    sucursal.columns = sucursal.columns.str.lower()\n",
    "    return sucursal\n",
    "\n",
    "def etl_prod(producto):\n",
    "    \n",
    "    producto=producto.astype({'marca':str,'nombre':str,'presentacion':str})\n",
    "    return producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de transformación a Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precios = etl(df_precios)\n",
    "df_precios1 = etl(df_precios1)\n",
    "df_precios2 = etl(df_precios2)\n",
    "df_precios3 = etl(df_precios3)\n",
    "df_delta = etl(df_delta)\n",
    "sucursal = etl_sucu(sucursal)\n",
    "producto=etl_prod(producto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgresql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga sucursal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carga se ha hecho con exito!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "cone = create_engine('postgresql://admin:admin1234@localhost:5432/productDb', pool_size=50, max_overflow=0)\n",
    "\n",
    "sucursal.to_sql(name='sucursal',con=cone, if_exists='append', index=False)\n",
    "print('La carga se ha hecho con exito!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carga se ha hecho con exito!\n"
     ]
    }
   ],
   "source": [
    "producto.to_sql(name='producto',con=cone, if_exists='append', index=False)\n",
    "print('La carga se ha hecho con exito!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de precios\n",
    "\n",
    "Aqui empezamos a tener problemas, tenemos por lo menos en el primer archivo (df_precios) 106K registros que no coinciden (mas abajo estan el merge para que vean)\n",
    "\n",
    "Yo diria que ya los matemos, y subamos eso asi jajja\n",
    "ok bye\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carga se ha hecho con exito!\n"
     ]
    }
   ],
   "source": [
    "df_precios.to_sql(name='precios',con=cone, if_exists='append', index=False)\n",
    "print('La carga se ha hecho con exito!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precios1.to_sql(name='precios', con=cone, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precios2.to_sql(name='precios', con=cone, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precios3.to_sql(name='precios', con=cone, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delta.to_sql(name='precios', con=cone, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_producto = 'ALTER TABLE producto ADD PRIMARY KEY(id);'\n",
    "tabla_sucursal = 'ALTER TABLE sucursal ADD PRIMARY KEY(id);'\n",
    "\n",
    "tabla_precio_2 = 'ALTER TABLE precios ADD FOREIGN KEY (sucursal_id) REFERENCES sucursal (id) MATCH SIMPLE ON UPDATE NO ACTION ON DELETE NO ACTION NOT VALID ;'\n",
    "tabla_precio_3 = 'ALTER TABLE precios ADD FOREIGN KEY (producto_id) REFERENCES producto (id) MATCH SIMPLE ON UPDATE NO ACTION ON DELETE NO ACTION NOT VALID;'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "   user='admin',\n",
    "   password='admin1234',\n",
    "   database='productDb',\n",
    "   port='5432'\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(tabla_producto)\n",
    "cur.execute(tabla_sucursal)\n",
    "cur.execute(tabla_precio_2)\n",
    "cur.execute(tabla_precio_3)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76c4de0fabe0602e2c2e9a8dee706b7aec8ef4c85d03ce0961883d90af556438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
